{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o dataset\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "previsores = breast_cancer.data\n",
    "classe = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divindo em conjuntos de teste e treino\n",
    "previsores_treinamento,previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando as camadas da rede neural\n",
    "\n",
    "classificador = Sequential()\n",
    "classificador.add(Dense(units=16, activation='relu', \n",
    "                        kernel_initializer='random_uniform', input_dim=30))\n",
    "classificador.add(Dense(units=16, activation='relu', \n",
    "                        kernel_initializer='random_uniform'))\n",
    "classificador.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucasarenhardt/.local/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - binary_accuracy: 0.9208 - loss: 0.2204 \n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - binary_accuracy: 0.9147 - loss: 0.1648\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - binary_accuracy: 0.9300 - loss: 0.2058\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - binary_accuracy: 0.9095 - loss: 0.2081\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - binary_accuracy: 0.9195 - loss: 0.1733\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8649 - loss: 0.3866 \n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - binary_accuracy: 0.9392 - loss: 0.1491\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - binary_accuracy: 0.9218 - loss: 0.2114\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - binary_accuracy: 0.9469 - loss: 0.1546\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - binary_accuracy: 0.9300 - loss: 0.1831\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - binary_accuracy: 0.9150 - loss: 0.1972\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - binary_accuracy: 0.9153 - loss: 0.2098\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - binary_accuracy: 0.9323 - loss: 0.2160\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9219 - loss: 0.2125\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - binary_accuracy: 0.9086 - loss: 0.2777\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - binary_accuracy: 0.9264 - loss: 0.2030\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - binary_accuracy: 0.8912 - loss: 0.2948\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - binary_accuracy: 0.8884 - loss: 0.2590\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - binary_accuracy: 0.9484 - loss: 0.1936\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - binary_accuracy: 0.9184 - loss: 0.2096\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - binary_accuracy: 0.9122 - loss: 0.2076\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - binary_accuracy: 0.9286 - loss: 0.2123\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - binary_accuracy: 0.9072 - loss: 0.2203\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - binary_accuracy: 0.9153 - loss: 0.2188\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - binary_accuracy: 0.8883 - loss: 0.2970\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.9178 - loss: 0.1859\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - binary_accuracy: 0.9213 - loss: 0.1928\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - binary_accuracy: 0.8948 - loss: 0.2492\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9125 - loss: 0.2432 \n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9095 - loss: 0.2411\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.9117 - loss: 0.1794\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - binary_accuracy: 0.9129 - loss: 0.2260\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - binary_accuracy: 0.9333 - loss: 0.1641\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - binary_accuracy: 0.9027 - loss: 0.2016\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9213 - loss: 0.2028\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - binary_accuracy: 0.9224 - loss: 0.1713\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - binary_accuracy: 0.9277 - loss: 0.2145\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - binary_accuracy: 0.9187 - loss: 0.2394\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8794 - loss: 0.3230\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - binary_accuracy: 0.9357 - loss: 0.1760\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - binary_accuracy: 0.8665 - loss: 0.3839\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - binary_accuracy: 0.9009 - loss: 0.2285\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - binary_accuracy: 0.8905 - loss: 0.3316\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - binary_accuracy: 0.9191 - loss: 0.2750\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.9219 - loss: 0.2183\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - binary_accuracy: 0.9114 - loss: 0.2207\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - binary_accuracy: 0.9170 - loss: 0.3320\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - binary_accuracy: 0.9124 - loss: 0.2564\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9148 - loss: 0.2007 \n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.9420 - loss: 0.1649\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - binary_accuracy: 0.8952 - loss: 0.3221\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - binary_accuracy: 0.9289 - loss: 0.2407\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - binary_accuracy: 0.9206 - loss: 0.2013\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - binary_accuracy: 0.8965 - loss: 0.4012\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9364 - loss: 0.1666\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - binary_accuracy: 0.9172 - loss: 0.1986\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - binary_accuracy: 0.9132 - loss: 0.2530\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - binary_accuracy: 0.8923 - loss: 0.2537\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - binary_accuracy: 0.9389 - loss: 0.1704\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9097 - loss: 0.2575 \n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - binary_accuracy: 0.9281 - loss: 0.1731\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - binary_accuracy: 0.9223 - loss: 0.1889\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - binary_accuracy: 0.9366 - loss: 0.2071\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - binary_accuracy: 0.9132 - loss: 0.2167\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - binary_accuracy: 0.9339 - loss: 0.2619\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - binary_accuracy: 0.8546 - loss: 0.4930\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - binary_accuracy: 0.9158 - loss: 0.2716\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - binary_accuracy: 0.9491 - loss: 0.1411\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - binary_accuracy: 0.9142 - loss: 0.2308\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - binary_accuracy: 0.9224 - loss: 0.2673\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - binary_accuracy: 0.9085 - loss: 0.2349\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - binary_accuracy: 0.9201 - loss: 0.2370\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - binary_accuracy: 0.8876 - loss: 0.2908\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9356 - loss: 0.2127\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - binary_accuracy: 0.9402 - loss: 0.1935\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - binary_accuracy: 0.9172 - loss: 0.2295\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - binary_accuracy: 0.9121 - loss: 0.3183\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - binary_accuracy: 0.8775 - loss: 0.4073\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - binary_accuracy: 0.9216 - loss: 0.2152\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - binary_accuracy: 0.8927 - loss: 0.2204\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - binary_accuracy: 0.8951 - loss: 0.3419\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - binary_accuracy: 0.9113 - loss: 0.2682\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - binary_accuracy: 0.9049 - loss: 0.3298\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - binary_accuracy: 0.9146 - loss: 0.2739\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - binary_accuracy: 0.9062 - loss: 0.3022\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9226 - loss: 0.2650 \n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - binary_accuracy: 0.8995 - loss: 0.2616\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - binary_accuracy: 0.9011 - loss: 0.3174\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - binary_accuracy: 0.8972 - loss: 0.2734\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - binary_accuracy: 0.9256 - loss: 0.1939\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - binary_accuracy: 0.9442 - loss: 0.1676\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.9360 - loss: 0.1597\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - binary_accuracy: 0.9210 - loss: 0.2604\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - binary_accuracy: 0.9322 - loss: 0.2637\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - binary_accuracy: 0.9204 - loss: 0.2726\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - binary_accuracy: 0.9127 - loss: 0.2519\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - binary_accuracy: 0.9092 - loss: 0.2478\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - binary_accuracy: 0.9148 - loss: 0.3504\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - binary_accuracy: 0.9330 - loss: 0.2222\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - binary_accuracy: 0.9062 - loss: 0.3328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72e2847e6cb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compilando a rede neural\n",
    "#aqui ocorre o ajuste dos pesos\n",
    "otimizador = keras.optimizers.Adam(learning_rate=0.001, decay=0.001, clipvalue=0.5)\n",
    "\n",
    "classificador.compile(optimizer=otimizador, loss='binary_crossentropy',\n",
    "                    metrics=['binary_accuracy'])\n",
    "\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.74513976e-02,  1.44335970e-01,  1.72514766e-01,\n",
      "        -9.72372293e-02,  4.85425070e-03,  3.24592255e-02,\n",
      "         5.46691520e-03,  9.10332054e-02, -3.57346684e-02,\n",
      "         3.40540498e-01, -1.05320327e-02, -1.42026404e-02,\n",
      "         2.28670277e-02,  6.73389211e-02, -3.40657122e-02,\n",
      "        -3.12805176e-02],\n",
      "       [ 4.46857549e-02, -3.37234000e-03,  9.03107002e-02,\n",
      "        -1.14191085e-01, -1.90098640e-02,  4.14858013e-03,\n",
      "         7.48681836e-03,  8.03471878e-02,  1.18537748e-03,\n",
      "        -1.30393207e-01, -2.79333480e-02, -6.15118444e-02,\n",
      "         3.68142165e-02, -4.92201112e-02, -3.53615284e-02,\n",
      "         8.94427299e-03],\n",
      "       [ 3.35082300e-02, -1.55347750e-01, -1.74947098e-01,\n",
      "         1.01268649e-01, -1.91866998e-02, -3.29753645e-02,\n",
      "        -2.56240107e-02, -1.76964387e-01, -5.51638417e-02,\n",
      "         2.07226396e-01, -4.93156910e-02,  3.40705067e-02,\n",
      "        -2.64589787e-02,  1.96728706e-02, -3.69962454e-02,\n",
      "         3.14374678e-02],\n",
      "       [-4.95185852e-02,  1.13503989e-02, -1.90095101e-02,\n",
      "         1.06626257e-01, -3.81832235e-02, -6.50382042e-03,\n",
      "         1.22474525e-02, -3.36341895e-02, -2.17839088e-02,\n",
      "         2.22370569e-02, -3.07701826e-02,  1.72421224e-02,\n",
      "         4.97011095e-03, -3.01385690e-02,  2.29569785e-02,\n",
      "         1.49634741e-02],\n",
      "       [-4.75288033e-02,  3.16292197e-01,  3.38109761e-01,\n",
      "        -1.67045519e-01, -3.27047594e-02,  2.98647545e-02,\n",
      "         1.38966246e-02,  2.26602390e-01, -6.59871101e-02,\n",
      "        -5.43769263e-02, -3.74868400e-02, -4.26077209e-02,\n",
      "        -3.81193049e-02, -1.83024332e-02,  4.90580089e-02,\n",
      "         4.63977940e-02],\n",
      "       [-4.05721180e-02,  1.88713062e+00,  1.82256103e+00,\n",
      "        -1.68962693e+00,  3.11601646e-02,  7.59857893e-03,\n",
      "        -1.54898632e-02,  1.79597402e+00,  1.31244078e-01,\n",
      "        -5.51930368e-01,  3.32165249e-02,  2.13279184e-02,\n",
      "        -4.87882867e-02, -4.90239888e-01,  3.48387100e-02,\n",
      "         2.21345164e-02],\n",
      "       [ 2.99654491e-02,  3.08096242e+00,  2.94115043e+00,\n",
      "        -2.79126716e+00, -3.72274742e-02, -6.72139972e-03,\n",
      "        -1.90099049e-03,  3.00783658e+00,  2.12994307e-01,\n",
      "        -8.43322277e-01,  2.22344734e-02,  5.41035160e-02,\n",
      "        -2.49934085e-02, -8.23766530e-01, -2.37895139e-02,\n",
      "        -2.89368872e-02],\n",
      "       [ 5.26553392e-03,  3.10810089e+00,  3.00248361e+00,\n",
      "        -2.73317504e+00, -6.07041270e-03,  3.34119238e-02,\n",
      "        -3.80738527e-02,  2.98485470e+00,  1.36289015e-01,\n",
      "        -3.51247281e-01,  3.27563025e-02,  1.24274082e-02,\n",
      "         2.13048942e-02, -6.84091747e-01,  3.48684303e-02,\n",
      "        -2.35669967e-02],\n",
      "       [-2.21072566e-02,  2.22024858e-01,  1.49543226e-01,\n",
      "        -1.88080240e-02,  6.51072338e-03, -7.16856867e-03,\n",
      "        -6.74327761e-02,  1.18598692e-01, -4.20203768e-02,\n",
      "        -6.36899024e-02,  1.50710009e-02, -2.47211065e-02,\n",
      "         6.08180836e-03,  9.44909826e-02, -4.98468541e-02,\n",
      "        -9.81054455e-03],\n",
      "       [-4.47005294e-02, -3.08346413e-02, -5.85042089e-02,\n",
      "         1.88152224e-01,  4.31328081e-02,  1.14760548e-03,\n",
      "        -4.68162224e-02, -8.17926154e-02, -5.92924953e-02,\n",
      "        -9.29235071e-02, -4.63763364e-02,  1.80385336e-02,\n",
      "        -4.11497727e-02,  1.41447380e-01, -3.08898576e-02,\n",
      "         2.83195041e-02],\n",
      "       [ 4.19648997e-02, -3.10705811e-01, -3.10333073e-01,\n",
      "         2.58384049e-01,  3.02744396e-02, -7.97239691e-03,\n",
      "        -6.74634415e-04, -3.65348101e-01, -4.37756889e-02,\n",
      "        -2.42506281e-01, -4.92861643e-02,  1.90347377e-02,\n",
      "        -2.94271708e-02,  2.30410658e-02,  1.76314823e-02,\n",
      "        -2.85429601e-02],\n",
      "       [-4.99575622e-02, -4.14438844e-01, -4.06225652e-01,\n",
      "         3.75345439e-01, -3.18788365e-03,  5.15580177e-04,\n",
      "        -1.83811951e-02, -2.98356980e-01, -3.57653163e-02,\n",
      "        -3.77543807e-01,  7.17813894e-03, -2.60818601e-02,\n",
      "         1.11911185e-02,  1.05234422e-01,  2.08084248e-02,\n",
      "         8.31985474e-03],\n",
      "       [ 4.85462062e-02,  3.21543723e-01,  2.67227232e-01,\n",
      "        -2.52842903e-01,  4.24222834e-02, -8.47993046e-03,\n",
      "        -1.52934361e-02,  2.16455713e-01,  3.75905521e-02,\n",
      "        -3.42548430e-01, -3.78600247e-02, -2.01619584e-02,\n",
      "        -2.09910627e-02, -4.05157171e-02, -4.97973822e-02,\n",
      "        -3.41680795e-02],\n",
      "       [-2.36550719e-03,  1.00053787e-01,  6.20811917e-02,\n",
      "        -1.30061746e-01, -3.62841599e-02, -3.89502048e-02,\n",
      "         1.33814279e-03,  8.94008130e-02,  2.92238463e-02,\n",
      "        -9.94121879e-02,  3.01044248e-02,  1.07579632e-02,\n",
      "        -1.74137950e-02, -2.61654705e-02, -3.05605773e-02,\n",
      "         2.01898813e-03],\n",
      "       [ 1.13911852e-02,  5.54982126e-01,  4.87586617e-01,\n",
      "        -3.47914934e-01, -3.98901328e-02,  1.84260309e-04,\n",
      "        -1.09059224e-02,  4.65341866e-01,  5.09956032e-02,\n",
      "        -2.50312656e-01,  4.45406549e-02,  2.61416994e-02,\n",
      "         2.60543264e-02, -5.10437004e-02,  1.05423443e-02,\n",
      "        -4.99813445e-02],\n",
      "       [ 1.14861242e-02,  1.22374463e+00,  1.22816372e+00,\n",
      "        -1.13626897e+00, -5.10048121e-04,  1.82726122e-02,\n",
      "        -4.18570377e-02,  1.21509671e+00,  9.68904123e-02,\n",
      "        -9.17507589e-01,  3.37586142e-02, -2.90735178e-02,\n",
      "         4.14830446e-03, -4.72506106e-01,  1.39880218e-02,\n",
      "        -1.55181885e-02],\n",
      "       [-4.63124514e-02,  1.22584414e+00,  1.25009906e+00,\n",
      "        -1.21824360e+00, -2.82855276e-02,  3.91402356e-02,\n",
      "         1.84653364e-02,  1.27503443e+00,  7.50653446e-02,\n",
      "        -1.05725944e+00,  3.36055495e-02, -8.46018083e-03,\n",
      "         9.03810188e-03, -4.96494323e-01, -2.35038158e-02,\n",
      "         2.17939131e-02],\n",
      "       [ 3.77466716e-02,  1.53512704e+00,  1.46089017e+00,\n",
      "        -1.31055987e+00, -3.31185944e-02, -4.54760194e-02,\n",
      "         2.40266211e-02,  1.49562728e+00,  1.30251627e-02,\n",
      "        -4.24841464e-01,  2.27346458e-02, -4.26606722e-02,\n",
      "         1.95815228e-02, -3.84299308e-01, -4.82767224e-02,\n",
      "         1.07447021e-02],\n",
      "       [ 2.94880383e-02,  4.41963188e-02,  5.61439395e-02,\n",
      "         3.86214107e-02, -3.90480049e-02,  3.25567611e-02,\n",
      "        -4.05990425e-03,  1.27053156e-01,  4.18859944e-02,\n",
      "        -3.90443474e-01, -1.61741003e-02,  1.87232010e-02,\n",
      "        -4.45067547e-02,  1.57658127e-03,  2.39668824e-02,\n",
      "         9.40890238e-03],\n",
      "       [ 3.80142368e-02,  3.85502845e-01,  3.26490462e-01,\n",
      "        -3.25603276e-01,  3.13943140e-02,  3.07232849e-02,\n",
      "        -4.82069626e-02,  3.94598395e-01,  1.16884053e-01,\n",
      "        -7.49213696e-01, -1.38503686e-02, -4.53856178e-02,\n",
      "        -4.87519614e-02, -2.03597203e-01,  3.94066311e-02,\n",
      "         2.60019340e-02],\n",
      "       [-2.97475215e-02,  6.90618381e-02,  1.49111226e-01,\n",
      "        -9.09298360e-02, -4.07916196e-02,  1.96990408e-02,\n",
      "         8.69988184e-03,  7.16021284e-02, -9.70291439e-03,\n",
      "         3.52434069e-01, -4.84384783e-02, -6.14953153e-02,\n",
      "        -2.99259908e-02,  9.62920710e-02, -3.73391993e-02,\n",
      "         1.09042414e-02],\n",
      "       [ 3.58912684e-02,  1.09148100e-01,  1.63066372e-01,\n",
      "        -2.22116381e-01,  4.05335911e-02,  1.92459933e-02,\n",
      "        -5.03479168e-02,  1.70220137e-01,  2.32559051e-02,\n",
      "        -1.75166875e-01,  1.89636238e-02,  1.90084986e-02,\n",
      "         4.06130403e-03, -3.03235389e-02, -1.32957324e-02,\n",
      "        -2.10279711e-02],\n",
      "       [-2.24762205e-02, -1.17165856e-01, -1.07956991e-01,\n",
      "         5.22310063e-02,  2.26728357e-02,  8.22464377e-03,\n",
      "        -5.63067058e-03, -1.03630908e-01,  1.40034119e-02,\n",
      "         1.21230625e-01,  1.88758858e-02, -5.02919555e-02,\n",
      "        -2.89646275e-02,  5.93241155e-02,  4.80530523e-02,\n",
      "         4.16224487e-02],\n",
      "       [-3.81045714e-02,  1.98375899e-02,  3.90657149e-02,\n",
      "         9.05972868e-02, -3.90102379e-02, -4.91468087e-02,\n",
      "        -2.66811512e-02,  5.32346666e-02,  7.71939708e-03,\n",
      "        -4.72978828e-03,  1.31956488e-03, -2.07628924e-02,\n",
      "        -2.46404540e-02, -2.79496470e-03, -2.05314159e-02,\n",
      "        -4.08347845e-02],\n",
      "       [ 6.17699698e-03,  5.61878622e-01,  5.30792236e-01,\n",
      "        -4.18889880e-01, -4.47456501e-02,  3.00038792e-02,\n",
      "        -1.62515156e-02,  5.03910840e-01,  8.48130416e-03,\n",
      "        -9.66170207e-02,  4.19465341e-02, -2.28916593e-02,\n",
      "        -1.13142654e-03,  8.99448246e-03,  4.88564409e-02,\n",
      "        -4.77568395e-02],\n",
      "       [ 4.74611782e-02,  2.29157376e+00,  2.19980693e+00,\n",
      "        -2.01014948e+00, -3.84476185e-02,  2.31706537e-02,\n",
      "         2.43723523e-02,  2.18139219e+00,  1.60966054e-01,\n",
      "        -7.38007367e-01,  3.34944390e-02,  4.05527651e-02,\n",
      "         2.81531736e-03, -6.54283524e-01, -2.60585789e-02,\n",
      "         4.57946397e-02],\n",
      "       [-1.24316439e-02,  2.60275149e+00,  2.55483723e+00,\n",
      "        -2.42572570e+00,  3.18358205e-02, -4.44748253e-03,\n",
      "         2.79925819e-02,  2.56878376e+00,  1.95319235e-01,\n",
      "        -8.60520959e-01,  3.81257050e-02, -9.57534369e-03,\n",
      "        -2.92541739e-02, -7.34949946e-01,  3.20222713e-02,\n",
      "        -4.50263880e-02],\n",
      "       [-3.74235883e-02,  2.49795032e+00,  2.39742398e+00,\n",
      "        -2.16430688e+00, -4.82738391e-02,  1.73634999e-02,\n",
      "        -3.41796875e-02,  2.36513686e+00,  1.29275650e-01,\n",
      "        -3.94057989e-01, -2.96567213e-02,  1.09472116e-02,\n",
      "        -2.14964747e-02, -5.76548755e-01,  4.69743647e-02,\n",
      "         8.56056064e-03],\n",
      "       [-1.88462865e-02,  4.94553953e-01,  5.58366477e-01,\n",
      "        -4.01981264e-01,  4.82338779e-02,  2.98758261e-02,\n",
      "        -2.23032422e-02,  4.66844678e-01,  3.47285680e-02,\n",
      "        -1.93455860e-01, -2.20206734e-02, -6.32127300e-02,\n",
      "        -2.98053622e-02, -1.04375601e-01, -2.27815397e-02,\n",
      "         2.97873355e-02],\n",
      "       [-8.03925097e-04,  6.09523714e-01,  5.99322677e-01,\n",
      "        -4.22466457e-01,  4.16113995e-02,  2.05189921e-02,\n",
      "         1.66502055e-02,  5.54915786e-01,  3.69954929e-02,\n",
      "        -3.22950065e-01,  9.65291262e-03, -6.71327114e-02,\n",
      "        -1.70994997e-02, -1.07088536e-01,  1.16625205e-02,\n",
      "         9.58571583e-03]], dtype=float32), array([ 0.        , -0.26421592, -0.3070904 ,  0.40725085,  0.        ,\n",
      "        0.        , -0.02018827, -0.36102033, -0.06159219,  0.18916288,\n",
      "        0.        , -0.01903319,  0.        ,  0.22321805,  0.        ,\n",
      "        0.        ], dtype=float32)]\n",
      "2\n",
      "[array([[ 4.8571337e-02,  2.1159425e-03,  4.2851079e-02,  4.3205027e-02,\n",
      "        -5.4643378e-03,  3.4588624e-02, -3.5496198e-02, -2.8212273e-02,\n",
      "        -4.5513026e-03, -5.8423392e-03,  8.7057836e-03, -5.6396611e-03,\n",
      "        -4.9168825e-02,  3.3068631e-02, -3.8325809e-02,  1.7028499e-02],\n",
      "       [-1.3256289e-02, -5.3546941e-01, -5.3511847e-02, -1.1624860e-01,\n",
      "        -4.6341281e-02, -2.9395521e-01,  4.9893329e-01, -2.3132456e-02,\n",
      "        -5.0794773e-02,  5.4452962e-01, -1.0200793e-01, -4.5150068e-02,\n",
      "         3.7460873e-01, -1.7699835e-01, -2.0733023e-02, -4.9518723e-02],\n",
      "       [-3.5735570e-02, -3.1034744e-01, -8.9665070e-02, -7.9966709e-02,\n",
      "        -2.6908755e-02, -1.8586177e-01,  1.8719254e-01,  2.1481898e-02,\n",
      "        -6.5745309e-02,  2.9279178e-01, -1.4358887e-01, -2.5647020e-02,\n",
      "         1.7577572e-03, -1.6938947e-01,  4.5911185e-03, -1.7501282e-02],\n",
      "       [-4.5185555e-02,  1.7398135e-01,  3.6068587e-03,  3.1623673e-02,\n",
      "        -1.8036367e-02,  4.0810060e-02,  4.7621127e-02, -1.5341569e-02,\n",
      "        -1.9488782e-02, -4.9408149e-02,  1.6582247e-02, -2.6639521e-02,\n",
      "        -3.3658408e-03,  3.5188820e-02, -9.1063604e-03,  7.4468232e-03],\n",
      "       [-4.0475838e-03, -2.4467720e-02,  7.3177218e-03,  4.5228489e-03,\n",
      "         4.0202048e-02, -1.1467792e-02, -2.1827830e-02, -4.5590688e-02,\n",
      "        -3.0636787e-02, -4.0526818e-02,  8.3396211e-03,  1.5605237e-02,\n",
      "        -2.5564099e-02, -1.0971356e-02, -4.1067243e-02, -2.0655429e-02],\n",
      "       [-3.7754893e-02,  3.0196104e-02, -1.7196797e-02, -3.2476388e-02,\n",
      "         4.5048300e-02, -2.5108887e-02, -5.9458390e-03,  3.5513043e-03,\n",
      "        -3.7979625e-02,  4.8191797e-02,  2.9514704e-02,  1.2533281e-02,\n",
      "        -4.6959043e-02,  2.3439351e-02,  3.1106520e-02, -3.2125749e-02],\n",
      "       [-2.5411619e-02,  1.4088144e-02, -2.3834547e-02, -7.7405684e-03,\n",
      "        -1.2904741e-02,  4.2403469e-04, -1.9621523e-02,  2.3961816e-02,\n",
      "         3.1448435e-02,  3.3011191e-02,  4.2167781e-03, -3.0336345e-02,\n",
      "         6.1415322e-03, -4.1449618e-02, -1.8880798e-02, -1.8720113e-02],\n",
      "       [-3.4993805e-02, -2.1728733e-01, -1.6832411e-01, -1.7779660e-01,\n",
      "        -7.1411561e-03, -7.5874783e-02,  1.6768427e-01, -2.3440290e-02,\n",
      "        -8.5057244e-03,  2.5806472e-01, -1.5298235e-01, -2.2769347e-03,\n",
      "        -1.8613681e-03, -1.3636614e-01, -3.7216891e-02, -4.5996394e-02],\n",
      "       [-3.6134042e-02,  3.2632679e-02, -3.7294630e-02,  7.1885311e-03,\n",
      "        -7.9247840e-03,  2.8458539e-02,  5.5200633e-02,  4.5011770e-02,\n",
      "        -1.3332417e-02,  4.5601979e-02, -6.3114548e-03, -3.7032355e-02,\n",
      "         2.9036046e-03, -1.3893253e-02, -2.5574494e-02, -3.5511058e-02],\n",
      "       [-1.7678961e-03,  7.2968468e-02, -4.2167682e-02, -1.6735479e-01,\n",
      "        -1.5376719e-02, -1.3919176e-01,  2.3327023e-01, -3.5318874e-02,\n",
      "         5.5795624e-03,  1.2618920e-01, -6.7648210e-02, -3.8607940e-03,\n",
      "         1.1861116e-02, -1.3070375e-01, -2.8404817e-03, -4.5822620e-02],\n",
      "       [-1.5254118e-02,  1.6546432e-02,  2.5492039e-02,  7.9607368e-03,\n",
      "        -3.2280851e-02, -6.6673756e-04,  1.1777841e-02, -4.7166277e-02,\n",
      "         1.1179995e-02, -1.1119414e-02,  1.0590710e-02,  3.4082178e-02,\n",
      "        -4.6094205e-02, -2.4621760e-02, -3.7629832e-02, -2.4399186e-02],\n",
      "       [ 7.9729408e-04, -1.7728545e-02,  1.3836716e-02,  2.3877979e-03,\n",
      "         4.4606242e-02, -4.4772945e-02, -2.4945803e-02, -8.6004958e-03,\n",
      "         1.3761297e-03,  2.9614886e-02, -6.9835251e-03, -1.1159014e-02,\n",
      "        -2.6746606e-02,  1.4686260e-02, -2.5074089e-02, -1.2403537e-02],\n",
      "       [ 4.1520309e-02, -1.7352045e-02, -1.6974162e-02,  1.9304249e-02,\n",
      "        -1.9928550e-02,  3.5949972e-02, -3.6318101e-02,  3.6626007e-02,\n",
      "        -4.1992091e-02, -3.4588348e-02,  4.7459137e-02,  6.2051304e-03,\n",
      "         3.4623966e-03,  2.7094830e-02, -4.1116476e-02, -2.7198792e-03],\n",
      "       [ 3.0531440e-02,  1.5661499e-02,  2.7608156e-02,  1.4773615e-03,\n",
      "         1.2463719e-03,  2.0025719e-02, -1.0675682e-02,  1.9458119e-02,\n",
      "        -6.1112698e-02,  3.9218020e-02,  1.0711951e-02, -4.2645514e-02,\n",
      "        -5.8973646e-03, -2.4959641e-02,  1.2109615e-02, -5.5469229e-04],\n",
      "       [ 5.3283200e-03,  2.7763117e-02,  3.4425411e-02,  3.7297383e-03,\n",
      "        -3.4221031e-02, -3.4991167e-02,  3.7767444e-02,  4.6593379e-02,\n",
      "        -6.8703778e-03,  2.1773685e-02, -3.7032031e-02, -8.7291971e-03,\n",
      "         1.5502300e-02, -1.3800837e-02, -4.4840325e-02, -2.6477862e-02],\n",
      "       [-1.3345648e-02, -3.8299333e-02, -1.5462972e-02,  3.2630686e-02,\n",
      "         1.5219454e-02, -3.9575588e-02, -1.7508149e-02, -1.9690407e-02,\n",
      "         4.9552772e-02, -2.9122127e-02, -1.0757018e-02,  4.9865399e-02,\n",
      "         3.5730600e-03,  2.8477300e-02,  1.9770134e-02, -3.1325687e-02]],\n",
      "      dtype=float32), array([ 0.        ,  0.33152094,  0.41501248,  0.4070401 , -0.01037974,\n",
      "        0.360917  , -0.4066392 ,  0.        , -0.01853884, -0.2697063 ,\n",
      "        0.35930705,  0.        , -0.03411164,  0.31591672,  0.        ,\n",
      "       -0.03536521], dtype=float32)]\n",
      "<bound method Layer.get_weights of <Dense name=dense_2, built=True>>\n"
     ]
    }
   ],
   "source": [
    "#obtendo os pesos de cada neurônio\n",
    "\n",
    "pesos0 = classificador.layers[0].get_weights()\n",
    "print(pesos0)\n",
    "print(len(pesos0))\n",
    "\n",
    "pesos1 = classificador.layers[1].get_weights()\n",
    "print(pesos1)\n",
    "\n",
    "pesos2 = classificador.layers[2].get_weights\n",
    "print(pesos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classe Teste</th>\n",
       "      <th>Previsoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Classe Teste  Previsoes\n",
       "0               1          1\n",
       "1               1          1\n",
       "2               0          0\n",
       "3               0          0\n",
       "4               0          0\n",
       "..            ...        ...\n",
       "138             1          1\n",
       "139             0          0\n",
       "140             1          1\n",
       "141             1          1\n",
       "142             1          0\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#realizando as previsoes da rede neural\n",
    "\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "previsoes = (previsoes > 0.5).astype(int)\n",
    "\n",
    "comparacao = pd.DataFrame(classe_teste)\n",
    "comparacao['Previsoes'] = previsoes\n",
    "comparacao.rename(columns={0: 'Classe Teste'}, inplace=True)\n",
    "comparacao = comparacao.sort_index(ascending=True)\n",
    "comparacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182\n",
      "[[46  0]\n",
      " [26 71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#medindo a precisao e imporimindo a matriz de confusao\n",
    "\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print(precisao)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8318 - loss: 0.4294 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4482928216457367, 0.8181818127632141]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#medindo a precisao de outra forma\n",
    "\n",
    "resultado = classificador.evaluate(previsores_teste, classe_teste)\n",
    "resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
